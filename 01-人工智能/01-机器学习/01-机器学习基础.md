## Index

<!-- TOC -->

* [1. 方差与偏差](#1-方差与偏差)
  * [1.1 导致偏差和方差的原因](#11-导致偏差和方差的原因)
  * [1.2 深度学习中的偏差与方差](#12-深度学习中的偏差与方差)
  * [1.3 偏差与方差的计算公式](#13-偏差与方差的计算公式)
  * [1.4 避免过拟合和欠拟合](#14-避免过拟合和欠拟合)
  * [1.5 偏差与方差的权衡（过拟合与模型复杂度的权衡）](#15-偏差与方差的权衡过拟合与模型复杂度的权衡)
  * [1.6 防止过拟合方法](#16-防止过拟合方法)
* [2. 生成模型与判别模型](#2-生成模型与判别模型)
* [3. 先验概率与后验概率](#3-先验概率与后验概率)
* [4. 超参数选择](#4-超参数选择)
  * [4.1 超参数有哪些](#41-超参数有哪些)
  * [4.2 确定调节范围](#42-确定调节范围)
    * [4.2.1 模型](#421-模型)
    * [4.2.2 学习率](#422-学习率)
    * [4.2.3 正则项系数](#423-正则项系数)
  * [4.3 交叉验证](#43-交叉验证)
    * [4.3.1 先粗调，再细调](#431-先粗调再细调)
    * [4.3.2 尝试在对数空间内进行调节](#432-尝试在对数空间内进行调节)
    * [4.3.3. 随机搜索参数值，而不是格点搜索](#433-随机搜索参数值而不是格点搜索)
  * [4.4 神经网路中的超参数](#44-神经网路中的超参数)
* [5. 余弦相似度（Cos距离）与欧氏距离的区别和联系](#5-余弦相似度cos距离与欧氏距离的区别和联系)
* [6. 混淆矩阵、模型度量指标：准确率、精确率、召回率、F1 值、ROC、AUC等](#6-混淆矩阵模型度量指标准确率精确率召回率f1-值rocauc等)
  * [6.1 分类评价指标](#61-分类评价指标)
  * [6.2 回归评价指标](#62-回归评价指标)
  * [6.3 解决评估指标鲁棒性问题](#63-解决评估指标鲁棒性问题)
* [7. 如何处理数据中的缺失值](#7-如何处理数据中的缺失值)
* [8. 介绍一个完整的机器学习项目流程](#8-介绍一个完整的机器学习项目流程)
* [9. 数据清洗与特征处理](#9-数据清洗与特征处理)
* [10. 关联规则挖掘的 3 个度量指标：支持度、置信度、提升度](#10-关联规则挖掘的-3-个度量指标支持度置信度提升度)
  * [10.1 规则的有效性：](#101-规则的有效性)
  * [10.2 <strong>判断规则的有效性</strong>](#102-判断规则的有效性)
* [11. 信息熵、KL 散度（相对熵）与交叉熵](#11-信息熵kl-散度相对熵与交叉熵)
  * [11.1 自信息与信息熵](#111-自信息与信息熵)
  * [11.2 相对熵（KL 散度）与交叉熵](#112-相对熵kl-散度与交叉熵)
* [12. 数据增强方法](#12-数据增强方法)
* [13. PCA原理](#13-pca原理)
* [14. 特征值和特征向量的含义](#14-特征值和特征向量的含义)
* [15. SGD 中 S(stochastic)代表什么](#15-sgd-中-sstochastic代表什么)
* [16. 数据预处理的方法](#16-数据预处理的方法)
  * [16.1 数据挖掘中使用的数据的原则](#161-数据挖掘中使用的数据的原则)
  * [16.2 常见的数据预处理方法](#162-常见的数据预处理方法)
* [17. 稀疏矩阵](#17-稀疏矩阵)
  * [17.1 稀疏的问题](#171-稀疏的问题)
  * [17.2 机器学习中的稀疏矩阵](#172-机器学习中的稀疏矩阵)
  * [17.3 处理稀疏矩阵](#173-处理稀疏矩阵)
  * [17.4 推荐系统](#174-推荐系统)
  * [17.5 [推荐系统]欧氏距离和余弦相似度](#175-推荐系统欧氏距离和余弦相似度)
* [18. 特征提取的方法和过程](#18-特征提取的方法和过程)
* [19. 监督学习／迁移学习／半监督学习／弱监督学习／非监督学习？](#19-监督学习迁移学习半监督学习弱监督学习非监督学习)
  * [19.1 机器学习算法的类型](#191-机器学习算法的类型)
  * [19.2 迁移学习](#192-迁移学习)
* [20. 树模型的特征选择中除了信息增益、信息增益比、基尼指数这三个外，还有哪些？](#20-树模型的特征选择中除了信息增益信息增益比基尼指数这三个外还有哪些)
* [21. 最小二乘与极大似然函数的关系？](#21-最小二乘与极大似然函数的关系)
* [22. 哪些机器学习算法不需要做归一化处理？](#22-哪些机器学习算法不需要做归一化处理)
* [23. 训练误差、泛化误差；过拟合、欠拟合；模型容量，表示容量，有效容量，最优容量的概念； 奥卡姆剃刀原则*](#23-训练误差泛化误差过拟合欠拟合模型容量表示容量有效容量最优容量的概念-奥卡姆剃刀原则)
* [24. 特征工程做的有哪些？非线性可分的情况怎么处理的？](#24-特征工程做的有哪些非线性可分的情况怎么处理的)
* [25. SVM的核函数了解多少？](#25-svm的核函数了解多少)
* [26. sigmoid函数的导函数的取值范围是多少？](#26-sigmoid函数的导函数的取值范围是多少)

<!-- /TOC -->

## 1. 方差与偏差

- **偏差**与**方差**分别是用于衡量一个模型**泛化误差**的两个方面；
  - 模型的**偏差**，指的是模型预测的**期望值**与**真实值**之间的差；
  - 模型的**方差**，指的是模型预测的**期望值**与**预测值**之间的差平方和；

- 在**监督学习**中，模型的**泛化误差**可**分解**为偏差、方差与噪声之和。

  <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=Err(x)&space;=&space;Bias^2&space;&plus;&space;Variance&space;&plus;&space;Noise" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Err(x)&space;=&space;Bias^2&space;&plus;&space;Variance&space;&plus;&space;Noise" title="Err(x) = Bias^2 + Variance + Noise" /></a></div>

- **偏差**用于描述模型的**拟合能力**
  **方差**用于描述模型的**稳定性**

<img src="_asset/Bias_Variance.png">

- 偏差：`Bias`反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，即算法本身的拟合能力
- 方差：`Variance`反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。反应预测的波动情况。
- 误差：`Err(x)` 也叫泛化误差
- 欠拟合会出现高偏差问题
- 过拟合会出现高方差问题

### 1.1 导致偏差和方差的原因

- 偏差通常是由于我们对学习算法做了错误的假设，或者模型的复杂度不够；
  - 比如真实模型是一个二次函数，而我们假设模型为一次函数，这就会导致偏差的增大（欠拟合）；
  - **由偏差引起的误差**通常在**训练误差**上就能体现，或者说训练误差主要是由偏差造成的
- 方差通常是由于模型的复杂度相对于训练集过高导致的；
  - 比如真实模型是一个简单的二次函数，而我们假设模型是一个高次函数，这就会导致方差的增大（过拟合）；
  - **由方差引起的误差**通常体现在测试误差相对训练误差的**增量**上。

### 1.2 深度学习中的偏差与方差

- 神经网络的拟合能力非常强，因此它的**训练误差**（偏差）通常较小；
- 但是过强的拟合能力会导致较大的方差，使模型的测试误差（**泛化误差**）增大；
- 因此深度学习的核心工作之一就是研究如何降低模型的泛化误差，这类方法统称为**正则化方法**。

### 1.3 偏差与方差的计算公式

- 记在**训练集 D** 上学得的模型为

  <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=f(x;D)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(x;D)" title="f(x;D)" /></a></div>

  模型的**期望预测**为

  <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\hat&space;f(x)&space;=&space;\Bbb&space;E_{D}[f(x;&space;D)]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\hat&space;f(x)&space;=&space;\Bbb&space;E_{D}[f(x;&space;D)]" title="\hat f(x) = \Bbb E_{D}[f(x; D)]" /></a></div>

- **偏差**（Bias）

  <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=bias^2(x)&space;=&space;(\hat&space;f(x)&space;-&space;y)^2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?bias^2(x)&space;=&space;(\hat&space;f(x)&space;-&space;y)^2" title="bias^2(x) = (\hat f(x) - y)^2" /></a></div>

  > **偏差**度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；

- **方差**（Variance）

  <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=var(x)&space;=&space;\Bbb&space;E_{D}[(f(x;&space;D)&space;-&space;\hat&space;f(x))^2]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?var(x)&space;=&space;\Bbb&space;E_{D}[(f(x;&space;D)&space;-&space;\hat&space;f(x))^2]" title="var(x) = \Bbb E_{D}[(f(x; D) - \hat f(x))^2]" /></a></div>

  > **方差**度量了同样大小的**训练集的变动**所导致的学习性能的变化，即刻画了数据扰动所造成的影响（模型的稳定性）；

- **噪声**则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。
- “**偏差-方差分解**”表明模型的泛化能力是由算法的能力、数据的充分性、任务本身的难度共同决定的。

### 1.4 避免过拟合和欠拟合

**避免欠拟合（刻画不够）**

- 寻找更好的特征-----具有代表性的
- 用更多的特征-----增大输入向量的维度

**避免过拟合（刻画太细，泛化太差）**

- 增大数据集合-----使用更多的数据，噪声点比重减少
- 减少数据特征-----减小数据维度，高维空间密度小
- 正则化方法-----即在对模型的目标函数（objective function）或代价函数（cost function）加上正则项
- 交叉验证方法

### 1.5 偏差与方差的权衡（过拟合与模型复杂度的权衡）

- 给定学习任务，

  - 当训练不足时，模型的**拟合能力不够**（数据的扰动不足以使模型产生显著的变化），此时**偏差**主导模型的泛化误差；
  - 随着训练的进行，模型的**拟合能力增强**（模型能够学习数据发生的扰动），此时**方差**逐渐主导模型的泛化误差；
  - 当训练充足后，模型的**拟合能力过强**（数据的轻微扰动都会导致模型产生显著的变化），此时即发生**过拟合**（训练数据自身的、非全局的特征也被模型学习了）

- 偏差和方差的关系和**模型容量**（模型复杂度）、**欠拟合**和**过拟合**的概念紧密相联

  <img src="_asset/Bias_Variance_1.png">

  - 当模型的容量增大（x 轴）时， 偏差（用点表示）随之减小，而方差（虚线）随之增大
  - 沿着 x 轴存在**最佳容量**，**小于最佳容量会呈现欠拟合**，**大于最佳容量会导致过拟合**。

  > 《深度学习》 5.4.4 权衡偏差和方差以最小化均方误差

### 1.6 防止过拟合方法

- 参数范数惩罚（Parameter Norm Penalties）
- 数据增强（Dataset Augmentation）
- 提前终止（Early Stopping）
- 参数绑定与参数共享（Parameter Tying and Parameter Sharing）
- Bagging 和其他集成方法
- Dropout
- 批标准化（Batch Normalization）

## 2. 生成模型与判别模型

- 监督学习的任务是学习一个模型，对给定的输入预测相应的输出

- 这个模型的一般形式为一个**决策函数**或一个**条件概率分布**（后验概率）：

  <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=Y&space;=&space;f(X)&space;or&space;P(Y|X)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Y&space;=&space;f(X)&space;or&space;P(Y|X)" title="Y = f(X) or P(Y|X)" /></a></div>

  - **决策函数**：输入 X 返回 Y；其中 Y 与一个**阈值**比较，然后根据比较结果判定 X 的类别
  - **条件概率分布**：输入 X 返回 **X 属于每个类别的概率**；将其中概率最大的作为 X 所属的类别

- 监督学习模型可分为**生成模型**与**判别模型**

  - 判别模型直接学习决策函数或者条件概率分布

    - 直观来说，**判别模型**学习的是类别之间的最优分隔面，反映的是不同类数据之间的差异

  - 生成模型学习的是联合概率分布`P(X,Y)`，然后根据条件概率公式计算`P(Y|X)`

    <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=P(Y|X)&space;=&space;\frac{P(X,Y)}{P(X)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(Y|X)&space;=&space;\frac{P(X,Y)}{P(X)}" title="P(Y|X) = \frac{P(X,Y)}{P(X)}" /></a></div>

**两者之间的联系**

- 由生成模型可以得到判别模型，但由判别模型得不到生成模型。

- 当存在“隐变量”时，只能使用生成模型

  > 隐变量：当我们找不到引起某一现象的原因时，就把这个在起作用，但无法确定的因素，叫“隐变量”

**优缺点**

- 判别模型
  - 优点
    - 直接面对预测，往往学习的准确率更高
    - 由于直接学习 `P(Y|X)` 或 `f(X)`，可以对数据进行各种程度的抽象，定义特征并使用特征，以简化学习过程
  - 缺点
    - 不能反映训练数据本身的特性
    - ...
- 生成模型
  - 优点
    - 可以还原出联合概率分布 `P(X,Y)`，判别方法不能
    - 学习收敛速度更快——即当样本容量增加时，学到的模型可以更快地收敛到真实模型
    - 当存在“隐变量”时，只能使用生成模型
  - 缺点
    - 学习和计算过程比较复杂

**常见模型**

- 判别模型
  - K 近邻、感知机（神经网络）、决策树、逻辑斯蒂回归、**最大熵模型**、SVM、提升方法、**条件随机场**
- 生成模型
  - 朴素贝叶斯、隐马尔可夫模型、混合高斯模型、贝叶斯网络、马尔可夫随机场

## 3. 先验概率与后验概率

> [先验概率，后验概率，似然概率，条件概率，贝叶斯，最大似然](https://blog.csdn.net/suranxu007/article/details/50326873) - CSDN博客

**条件概率**（似然概率）

- 一个事件发生后另一个事件发生的概率。
- 一般的形式为 `P(X|Y)`，表示 y 发生的条件下 x 发生的概率。
- 有时为了区分一般意义上的**条件概率**，也称**似然概率**

**先验概率**

- 事件发生前的预判概率
- 可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。
- 一般都是**单独事件**发生的概率，如 `P(A)`、`P(B)`。

**后验概率**

- 基于先验概率求得的**反向条件概率**，形式上与条件概率相同（若 `P(X|Y)` 为正向，则 `P(Y|X)` 为反向）

**贝叶斯公式**

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=P(Y|X)&space;=&space;\frac{P(X|Y)&space;*&space;P(Y)}{P(X)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(Y|X)&space;=&space;\frac{P(X|Y)&space;*&space;P(Y)}{P(X)}" title="P(Y|X) = \frac{P(X|Y) * P(Y)}{P(X)}" /></a></div>

**最大似然理论：**

认为`P(x|y)`最大的类别`y`，就是当前文档所属类别。即`Max P(x|y) = Max p(x1|y)*p(x2|y)*...p(xn|y), for all y`

**贝叶斯理论：**

认为需要增加先验概率`p(y)`，因为有可能某个`y`是很稀有的类别几千年才看见一次，即使`P(x|y)`很高，也很可能不是它。

所以`y = Max P(x|y) * P(y)`,其中`p(y)`一般是数据集里统计出来的。

## 4. 超参数选择

> [超参数的选择与交叉验证](https://blog.csdn.net/u013709270/article/details/75212750) - CSDN博客
>
> [十、如何选择神经网络的超参数](https://blog.csdn.net/dugudaibo/article/details/77366245) - CSDN博客

**Grid Search**

- 网格搜索
- 在高维空间中对一定区域进行遍历

**Random Search**

- 在高维空间中随机选择若干超参数

### 4.1 超参数有哪些
与超参数对应的是参数。参数是可以在模型中通过BP（反向传播）进行更新学习的参数，例如各种权值矩阵，偏移量等等。超参数是需要进行程序员自己选择的参数，无法学习获得。 

常见的超参数有模型（SVM，Softmax，Multi-layer Neural Network,…)，迭代算法（Adam,SGD,…)，学习率（learning rate)(不同的迭代算法还有各种不同的超参数，如beta1,beta2等等，但常见的做法是使用默认值，不进行调参）,正则化方程的选择(L0,L1,L2)，正则化系数，dropout的概率等等。

### 4.2 确定调节范围

超参数的种类多，调节范围大，需要先进行简单的测试确定调参范围。

#### 4.2.1 模型
模型的选择很大程度上取决于具体的实际问题，但必须通过几项基本测试。 

首先，模型必须可以正常运行，即代码编写正确。可以通过第一个epoch的loss估计，即估算第一个epoch的loss，并与实际结果比较。**注意此过程需要设置正则项系数为0，因为正则项引入的loss难以估算**。 

其次，**模型必须可以对于小数据集过拟合，即得到loss接近于0，accuracy接近于1的模型**。否则应该尝试其他或者更复杂的模型。 

最后，**如果 val_acc 与 acc 相差很小，可能是因为模型复杂度不够，需要尝试更为复杂的模型。**

#### 4.2.2 学习率

- loss 基本不变：学习率过低 

- loss 震动明显或者溢出：学习率过高 

根据以上两条原则，可以得到学习率的大致范围。

#### 4.2.3 正则项系数

- val_acc 与 acc 相差较大：正则项系数过小 
- loss 逐渐增大：正则项系数过大 

根据以上两条原则，可以得到正则项系数的大致范围。

### 4.3 交叉验证

对于训练集再次进行切分，得到训练集以及验证集。通过训练集训练得到的模型，在验证集验证，从而确定超参数。（选取在验证集结果最好的超参数） 

交叉验证的具体实例详见CS231n作业笔记1.7：基于特征的图像分类之调参和CS231n作业笔记1.2: KNN的交叉验证。

#### 4.3.1 先粗调，再细调

先通过数量少，间距大的粗调确定细调的大致范围。然后在小范围内部进行间距小，数量大的细调。

#### 4.3.2 尝试在对数空间内进行调节

即在对数空间内部随机生成测试参数，而不是在原空间生成，通常用于学习率以及正则项系数等的调节。出发点是该超参数的指数项对于模型的结果影响更显著；而同阶的数据之间即便原域相差较大，对于模型结果的影响反而不如不同阶的数据差距大。

#### 4.3.3. 随机搜索参数值，而不是格点搜索

<img src="_asset/RandomSearchVSGridSearch.png">

通过随机搜索，可以更好的发现趋势。图中所示的是通过随机搜索可以发现数据在某一维上的变化更加明显，得到明显的趋势。

### 4.4 神经网路中的超参数

1. 学习率 `η`
2. 正则化参数 `λ`
3. 神经网络的层数 `L`
4. 每一个隐层中神经元的个数 `j`
5. 学习的回合数 `Epoch`
6. 小批量数据 `minibatch` 的大小
7. 输出神经元的编码方式
8. 代价函数的选择
9. 权重初始化的方法
10. 神经元激活函数的种类
11. 参加训练模型数据的规模

## 5. 余弦相似度（Cos距离）与欧氏距离的区别和联系

> [欧氏距离和余弦相似度的区别是什么？](https://www.zhihu.com/question/19640394) - 知乎

- 欧式距离和余弦相似度都能度量 2 个向量之间的相似度
- 放到向量空间中看，欧式距离衡量两点之间的**直线距离**，而余弦相似度计算的是两个向量之间的**夹角**
- **没有归一化时**，欧式距离的范围是 `(0, +∞]`，而余弦相似度的范围是` (0, 1]`；余弦距离是计算**相似程度**，而欧氏距离计算的是**相同程度**（对应值的相同程度）
- **归一化的情况下**，可以将空间想象成一个超球面（三维），欧氏距离就是球面上两点的直线距离，而向量余弦值等价于两点的球面距离，本质是一样。

## 6. 混淆矩阵、模型度量指标：准确率、精确率、召回率、F1 值、ROC、AUC等

> [机器学习之分类性能度量指标 : ROC曲线、AUC值、正确率、召回率](https://www.jianshu.com/p/c61ae11cc5f6) - 简书
>
> [分类 (Classification)：ROC 和曲线下面积](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=zh-cn)

<img src="_asset/机器学习性能评估指标.png">

### 6.1 分类评价指标

**混淆矩阵**

- True Positive(TP)：将正类预测为正类的数量.
- True Negative(TN)：将负类预测为负类的数量.
- False Positive(FP)：将负类预测为正类数 → 误报 (Type I error).
- False Negative(FN)：将正类预测为负类数 → 漏报 (Type II error).

<img src="_asset/混肴矩阵.png">

**准确率**（accuracy）

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=ACC&space;=&space;\frac{TP&space;&plus;&space;TN}{TP&space;&plus;&space;TN&space;&plus;&space;FP&space;&plus;&space;FN}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?ACC&space;=&space;\frac{TP&space;&plus;&space;TN}{TP&space;&plus;&space;TN&space;&plus;&space;FP&space;&plus;&space;FN}" title="ACC = \frac{TP + TN}{TP + TN + FP + FN}" /></a></div>

**精确率**（precision）【查准率】

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=P&space;=&space;\frac{TP}{TP&space;&plus;&space;FP}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P&space;=&space;\frac{TP}{TP&space;&plus;&space;FP}" title="P = \frac{TP}{TP + FP}" /></a></div>

> 准确率与精确率的区别：
>
> > 在正负样本不平衡的情况下，**准确率**这个评价指标有很大的缺陷。比如在互联网广告里面，点击的数量是很少的，一般只有千分之几，如果用acc，即使全部预测成负类（不点击）acc 也有 99% 以上，没有意义。

**召回率**（recall, sensitivity, true positive rate）【查全率】

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=R&space;=&space;\frac{TP}{TP&space;&plus;&space;FN}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?R&space;=&space;\frac{TP}{TP&space;&plus;&space;FN}" title="R = \frac{TP}{TP + FN}" /></a></div>

**F1值**——精确率和召回率的调和均值

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=\frac{2}{F_{1}}&space;=&space;\frac{1}{P}&space;&plus;&space;\frac{1}{R}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\frac{2}{F_{1}}&space;=&space;\frac{1}{P}&space;&plus;&space;\frac{1}{R}" title="\frac{2}{F_{1}} = \frac{1}{P} + \frac{1}{R}" /></a></div>

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=F_{1}&space;=&space;\frac{2TP}{2TP&space;&plus;&space;FP&space;&plus;&space;FN}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?F_{1}&space;=&space;\frac{2TP}{2TP&space;&plus;&space;FP&space;&plus;&space;FN}" title="F_{1} = \frac{2TP}{2TP + FP + FN}" /></a></div>

> 只有当精确率和召回率都很高时，F1值才会高

**ROC**

**ROC曲线**：接收者操作特征曲线（[receiver operating characteristic curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)），是反映敏感性和特异性连续变量的综合指标，roc曲线上每个点反映着对同一信号刺激的感受性。

对于分类器，或者说分类算法，评价指标主要有precision，recall，F-score等，以及这里要讨论的ROC和AUC。下图是一个ROC曲线的示例：

<img src="_asset/ROC.png">

- 横坐标：**1-Specificity**，伪正类率(False positive rate， FPR)，**预测为正但实际为负**的样本占**所有负例样本**的比例；

- 纵坐标：**Sensitivity**，真正类率(True positive rate， TPR)，**预测为正且实际为正**的样本占**所有正例样本**的比例。

在一个二分类模型中，假设采用逻辑回归分类器，其给出针对每个实例为正类的概率，那么通过设定一个阈值如0.6，概率大于等于0.6的为正类，小于0.6的为负类。对应的就可以算出一组(FPR,TPR)，在平面中得到对应坐标点。随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着真正的负实例，即TPR和FPR会同时增大。阈值最大时，对应坐标点为(0,0)，阈值最小时，对应坐标点(1,1)。

如下面这幅图，(a)图中实线为ROC曲线，线上每个点对应一个阈值。

<img src="_asset/ROC曲线和它相关的比率.png">

(a) 理想情况下，TPR应该接近1，FPR应该接近0。ROC曲线上的每一个点对应于一个threshold，对于一个分类器，每个threshold下会有一个TPR和FPR。比如Threshold最大时，TP=FP=0，对应于原点；Threshold最小时，TN=FN=1，对应于右上角的点(1,1)。
(b) P和N得分不作为特征间距离d的一个函数，随着阈值theta增加，TP和FP都增加。

- 横轴FPR：1-TNR，1-Specificity，FPR越大，预测正类中实际负类越多。
- 纵轴TPR：Sensitivity(正类覆盖率)，TPR越大，预测正类中实际正类越多。
- 理想目标：TPR=1，FPR=0，即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。

<img src="_asset/ROC坐标系里的店如何移动.png">

**AUC**

AUC ([Area Under Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)) 被定义为**ROC曲线下的面积**，显然这个面积的数值**不会大于1**。又由于ROC曲线一般都处于 `y=x` 这条直线的上方，所以**AUC的取值范围一般在0.5和1之间**。

**使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。**

AUC的计算有两种方式，**梯形法**和**ROC AUCH法**，都是以逼近法求近似值，具体见[wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)。

**AUC意味着什么**

那么AUC值的含义是什么呢？根据(Fawcett, 2006)，AUC的值的含义是：

> The AUC value is equivalent to the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.

这句话有些绕，我尝试解释一下：首先AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。当然，**AUC值越大，当前的分类算法越有可能将正样本排在负样本前面，即能够更好的分类**。

从AUC判断分类器（预测模型）优劣的标准：

- AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。
- 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
- AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
- AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

三种AUC值示例：

<img src="_asset/AUC.png">

简单说：**AUC值越大的分类器，正确率越高**。

**为什么使用ROC曲线**

既然已经这么多评价标准，为什么还要使用ROC和AUC呢？

因为ROC曲线有个很好的特性：**当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变**。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。

### 6.2 回归评价指标

> [机器学习评估指标](https://zhuanlan.zhihu.com/p/36305931) - 知乎
>
> [机器学习-浅谈模型评估的方法和指标](https://www.jianshu.com/p/498ea0d8017d) - 简书

**MAE（平均绝对误差）**

平均绝对误差MAE（Mean Absolute Error）又被称为 **L1范数损失**。(`n = m -1`)

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=MAE(y,\hat{y})&space;=&space;\frac{1}{m}\sum_{i=1}^{n}|y_i&space;-&space;\hat{y_i}|" target="_blank"><img src="https://latex.codecogs.com/gif.latex?MAE(y,\hat{y})&space;=&space;\frac{1}{m}\sum_{i=1}^{n}|y_i&space;-&space;\hat{y_i}|" title="MAE(y,\hat{y}) = \frac{1}{m}\sum_{i=1}^{n}|y_i - \hat{y_i}|" /></a></div>

MAE有哪些不足？

- MAE虽能较好衡量回归模型的好坏，**但是绝对值的存在导致函数不光滑，在某些点上不能求导**，可以考虑将绝对值改为残差的平方，这就是均方误差。

**MSE（均方误差）**

均方误差MSE（Mean Squared Error）又被称为 **L2范数损失 **。

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=MSE(y,\hat{y})&space;=&space;\frac{1}{m}\sum_{i=1}^{m}(y_i&space;-&space;\hat{y_i})^2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?MSE(y,\hat{y})&space;=&space;\frac{1}{m}\sum_{i=1}^{m}(y_i&space;-&space;\hat{y_i})^2" title="MSE(y,\hat{y}) = \frac{1}{m}\sum_{i=1}^{m}(y_i - \hat{y_i})^2" /></a></div>

还有没有比MSE更合理一些的指标？

- 由于MSE与我们的目标变量的量纲不一致，**为了保证量纲一致性，我们需要对MSE进行开方 **。

**RMSE（均方根误差）**

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=RMSE(y,\hat{y})&space;=&space;\sqrt{\frac{1}{m}\sum_{i=1}^{m}(y_i&space;-&space;\hat{y_i})^2}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?RMSE(y,\hat{y})&space;=&space;\sqrt{\frac{1}{m}\sum_{i=1}^{m}(y_i&space;-&space;\hat{y_i})^2}" title="RMSE(y,\hat{y}) = \sqrt{\frac{1}{m}\sum_{i=1}^{m}(y_i - \hat{y_i})^2}" /></a></div>

RMSE有没有不足的地方？有没有规范化（无量纲化的指标）？

- 上面的几种衡量标准的取值大小与具体的应用场景有关系，很难定义统一的规则来衡量模型的好坏。比如说利用机器学习算法预测上海的房价RMSE在2000元，我们是可以接受的，但是当四五线城市的房价RMSE为2000元，我们还可以接受吗？下面介绍的**决定系数就是一个无量纲化的指标**。

**R^2（决定系数）**

变量之所以有价值，就是因为变量是变化的。什么意思呢？比如说一组因变量为[0, 0, 0, 0, 0]，显然该因变量的结果是一个常数0，我们也没有必要建模对该因变量进行预测。假如一组的因变量为[1, 3, 7, 10, 12]，该因变量是变化的，也就是有变异，因此需要通过建立回归模型进行预测。这里的变异可以理解为一组数据的方差不为0。

**决定系数又称为`R^2 score`，反映因变量的全部变异能通过回归关系被自变量解释的比例。**

<img src="_asset/R2.png">

- 如果结果是0，就说明模型预测不能预测因变量。

- 如果结果是1。就说明是函数关系。 

- 如果结果是0-1之间的数，就是我们模型的好坏程度。 

化简上面的公式 ,分子就变成了我们的均方误差MSE，下面分母就变成了方差:

<img src="_asset/R2_1.png">

**以上评估指标有没有缺陷，如果有，该怎样改进？**

以上的评估指标是基于误差的均值对进行评估的，均值对异常点（outliers）较敏感，**如果样本中有一些异常值出现，会对以上指标的值有较大影响，即均值是非鲁棒的**。

### 6.3 解决评估指标鲁棒性问题

我们通常用以下两种方法解决评估指标的鲁棒性问题：

- 剔除异常值
- 设定一个相对误差 ，当该值超过一定的阈值时，则认为其是一个异常点，剔除这个异常点，将异常点剔除之 后。再计算平均误差来对模型进行评价。
- 使用误差的分位数来代替
- 如利用中位数来代替平均数。例如 MAPE:

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=MAPE&space;=&space;median(|y_i&space;-&space;\hat{y_i}|&space;/&space;y_i)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?MAPE&space;=&space;median(|y_i&space;-&space;\hat{y_i}|&space;/&space;y_i)" title="MAPE = median(|y_i - \hat{y_i}| / y_i)" /></a></div>

MAPE是一个相对误差的中位数，当然也可以使用别的分位数。

## 7. 如何处理数据中的缺失值

可以分为以下 2 种情况：

1. **缺失值较多**

   - 直接舍弃该列特征，否则可能会带来较大的噪声，从而对结果造成不良影响。

2. **缺失值较少**

   - 当缺失值较少（<10%）时，可以考虑对缺失值进行填充，以下是几种常用的填充策略：

   1. 用一个**异常值**填充（比如 0），将缺失值作为一个特征处理

      `data.fillna(0)`

   2. 用**均值**|**条件均值**填充

      > 如果数据是不平衡的，那么应该使用条件均值填充
      >
      > 所谓**条件均值**，指的是与缺失值所属标签相同的所有数据的均值

      `data.fillna(data.mean())`

   3. 用相邻数据填充

      ```
      # 用前一个数据填充
      data.fillna(method='pad')
      # 用后一个数据填充
      data.fillna(method='bfill') 
      ```

   4. 插值

      `data.interpolate()`

   5. 拟合

      > 简单来说，就是将缺失值也作为一个预测问题来处理：将数据分为正常数据和缺失数据，对有值的数据采用随机森林等方法拟合，然后对有缺失值的数据进行预测，用预测的值来填充。

## 8. 介绍一个完整的机器学习项目流程

1. **数学抽象**

   明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。

   这里的抽象成数学问题，指的是根据数据明确任务目标，是分类、还是回归，或者是聚类。

2. **数据获取**

   数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。

   数据要有代表性，否则必然会过拟合。

   对于分类问题，数据偏斜不能过于严重（平衡），不同类别的数据数量不要有数个数量级的差距。

   对数据的量级要有一个评估，多少个样本，多少个特征，据此估算出内存需求。如果放不下就得考虑改进算法或者使用一些降维技巧，或者采用分布式计算。

3. **预处理与特征选择**

   良好的数据要能够提取出良好的特征才能真正发挥效力。

   预处理/数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。

   筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。

4. **模型训练与调优**

   直到这一步才用到我们上面说的算法进行训练。

   现在很多算法都能够封装成黑盒使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。

5. **模型诊断**

   如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。

   过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。

   误差分析也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题......

   诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。

6. **模型融合/集成**

   一般来说，模型融合后都能使得效果有一定提升。而且效果很好。

   工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。

7. **上线运行**

   这一部分内容主要跟工程实现的相关性更大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。

   这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有多实践，多积累项目经验，才会有自己更深刻的认识。

## 9. 数据清洗与特征处理

> [数据清洗方法](./note/数据清洗方法)
>
> [机器学习中的数据清洗与特征处理综述](https://tech.meituan.com/machinelearning_data_feature_process.html) - 美团技术团队
>
> [【机器学习InAction系列】数据清洗与特征处理综述](https://cloud.tencent.com/developer/article/1057749) - 腾讯云

<img src="_asset/数据清洗与特征处理.jpg">

## 10. 关联规则挖掘的 3 个度量指标：支持度、置信度、提升度

**支持度**（Support）

- `X → Y `的支持度表示项集 `{X,Y} `在总项集中出现的概率

  <a href="https://www.codecogs.com/eqnedit.php?latex=Support(X&space;\rightarrow&space;Y)&space;=&space;\frac{P(X&space;\bigcup&space;Y)}{P(I)}&space;=&space;\frac{num(X&space;\bigcup&space;Y)}{num(I)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Support(X&space;\rightarrow&space;Y)&space;=&space;\frac{P(X&space;\bigcup&space;Y)}{P(I)}&space;=&space;\frac{num(X&space;\bigcup&space;Y)}{num(I)}" title="Support(X \rightarrow Y) = \frac{P(X \bigcup Y)}{P(I)} = \frac{num(X \bigcup Y)}{num(I)}" /></a>

- 其中，`I` 表示总事务集，`num()`表示事务集中特定项集出现的次数，`P(X)=num(X)/num(I)`

**置信度**（Confidence）

- `X → Y `的置信度表示在先决条件 `X` 发生的情况下，由规则 `X → Y` 推出 `Y` 的概率。

  <a href="https://www.codecogs.com/eqnedit.php?latex=Confidence(X&space;\rightarrow&space;Y)&space;=&space;P(Y|X)&space;=&space;\frac{P(X&space;\cup&space;Y)}{P(X)}&space;=&space;\frac{num(X&space;\cup&space;Y)}{num(X)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Confidence(X&space;\rightarrow&space;Y)&space;=&space;P(Y|X)&space;=&space;\frac{P(X&space;\cup&space;Y)}{P(X)}&space;=&space;\frac{num(X&space;\cup&space;Y)}{num(X)}" title="Confidence(X \rightarrow Y) = P(Y|X) = \frac{P(X \cup Y)}{P(X)} = \frac{num(X \cup Y)}{num(X)}" /></a>

**提升度**（Lift）

- `X → Y` 的提升度表示含有 `X` 的条件下，同时含有 `Y` 的概率，与 `Y` 总体发生的概率之比。

  <a href="https://www.codecogs.com/eqnedit.php?latex=\begin{align*}&space;Lift(X&space;\rightarrow&space;Y)&space;&=&space;\frac{P(Y|X)}{P(Y)}&space;=&space;\frac{Confidence(X&space;\rightarrow&space;Y)}{num(Y)&space;/&space;num(I)}&space;\\&space;&=&space;\frac{P(X&space;\cup&space;Y)}{P(X)P(Y)}&space;=&space;\frac{num(X&space;\cup&space;Y)num(I)}{num(X)num(Y)}&space;\end{align*}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;Lift(X&space;\rightarrow&space;Y)&space;&=&space;\frac{P(Y|X)}{P(Y)}&space;=&space;\frac{Confidence(X&space;\rightarrow&space;Y)}{num(Y)&space;/&space;num(I)}&space;\\&space;&=&space;\frac{P(X&space;\cup&space;Y)}{P(X)P(Y)}&space;=&space;\frac{num(X&space;\cup&space;Y)num(I)}{num(X)num(Y)}&space;\end{align*}" title="\begin{align*} Lift(X \rightarrow Y) &= \frac{P(Y|X)}{P(Y)} = \frac{Confidence(X \rightarrow Y)}{num(Y) / num(I)} \\ &= \frac{P(X \cup Y)}{P(X)P(Y)} = \frac{num(X \cup Y)num(I)}{num(X)num(Y)} \end{align*}" /></a>

### 10.1 规则的有效性：

- 满足最小支持度和最小置信度的规则，叫做“强关联规则”

  > 最小支持度和最小置信度是人工设置的阈值

- `Lift(X→Y) > 1` 的 X→Y 是有效的强关联规则

- `Lift(X→Y) <=1` 的 X→Y 是有效的强关联规则

- 特别地，`Lift(X→Y) = 1` 时，X 与 Y 相互独立。

### 10.2 **判断规则的有效性**

问题：已知有1000名顾客买年货，分为甲乙两组，每组各500人，其中甲组有500人买了茶叶，同时又有450人买了咖啡；乙组有450人买了咖啡，如表所示，请问“茶叶→咖啡”是一条有效的关联规则吗？

| 组次          | 买茶叶的人数 | 买咖啡的人数 |
| ------------- | ------------ | ------------ |
| 甲组（500人） | 500          | 450          |
| 乙组（500人） | 0            | 450          |

答：

- “茶叶→咖啡”的支持度：`Support(X→Y) = 450 / 1000 = 45%`
- “茶叶→咖啡”的置信度：`Confidence(X→Y) = 450 / 500 = 90%`
- “茶叶→咖啡”的提升度：`Lift(X→Y) = 90% / 90% = 1`

由于提升度 `Lift(X→Y) = 1`，表示 `X` 与 `Y` 相互独立。也就是说，是否购买咖啡，与是否购买茶叶无关联。规则“茶叶→咖啡”不成立，或者说几乎没有关联，虽然它的置信度高达90%，但它不是一条有效的关联规则。

## 11. 信息熵、KL 散度（相对熵）与交叉熵

什么是熵？

- 熵是为消除不确定性所需要获得的信息量

> 《深度学习》 3.13 信息论

信息论的基本想法是一个不太可能的事件居然发生了，要比一个非常可能的事件发生，能提供更多的信息。

该想法可描述为以下性质：

1. 非常可能发生的事件信息量要比较少，并且极端情况下，确保能够发生的事件应该没有信息量。
2. 比较不可能发生的事件具有更高的信息量。
3. 独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，应该是投掷一次硬币正面朝上的信息量的两倍。

### 11.1 自信息与信息熵

自信息（self-information）是一种量化以上性质的函数，定义一个事件 x 的自信息为：

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=I(x)&space;=&space;-logP(x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?I(x)&space;=&space;-logP(x)" title="I(x) = -logP(x)" /></a></div>

> 当该对数的底数为 e 时，单位为奈特（nats，本书标准）；当以 2 为底数时，单位为比特（bit）或香农（shannons）

自信息只处理单个的输出。此时，用信息熵（Information-entropy）来对整个概率分布中的不确定性总量进行量化：

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=H(\mathrm{X})&space;=&space;\mathbb{E}_{\mathrm{X}&space;\sim&space;P}[I(x)]&space;=&space;-&space;\sum_{x&space;\in&space;\mathrm{X}}P(x)&space;\log&space;P(x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?H(\mathrm{X})&space;=&space;\mathbb{E}_{\mathrm{X}&space;\sim&space;P}[I(x)]&space;=&space;-&space;\sum_{x&space;\in&space;\mathrm{X}}P(x)&space;\log&space;P(x)" title="H(\mathrm{X}) = \mathbb{E}_{\mathrm{X} \sim P}[I(x)] = - \sum_{x \in \mathrm{X}}P(x) \log P(x)" /></a></div>

> 信息熵也称香农熵（Shannon entropy）
>
> 信息论中，记 `0log0 = 0`

### 11.2 相对熵（KL 散度）与交叉熵

P 对 Q 的 **KL散度**（Kullback-Leibler divergence）：

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=D_P(Q)&space;=&space;\mathbb{E}_{\mathrm{X}&space;\sim&space;P}&space;\left[&space;\log&space;\frac{P(x)}{Q(x)}&space;\right]&space;=&space;\sum_{x&space;\in&space;\mathrm{X}}P(x)&space;\left[&space;\log&space;P(x)&space;-&space;\log&space;Q(x)&space;\right]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?D_P(Q)&space;=&space;\mathbb{E}_{\mathrm{X}&space;\sim&space;P}&space;\left[&space;\log&space;\frac{P(x)}{Q(x)}&space;\right]&space;=&space;\sum_{x&space;\in&space;\mathrm{X}}P(x)&space;\left[&space;\log&space;P(x)&space;-&space;\log&space;Q(x)&space;\right]" title="D_P(Q) = \mathbb{E}_{\mathrm{X} \sim P} \left[ \log \frac{P(x)}{Q(x)} \right] = \sum_{x \in \mathrm{X}}P(x) \left[ \log P(x) - \log Q(x) \right]" /></a></div>

**KL 散度在信息论中度量的是那个直观量**：

在离散型变量的情况下， KL 散度衡量的是，当我们使用一种被设计成能够使得概率分布 Q 产生的消息的长度最小的编码，发送包含由概率分布 P 产生的符号的消息时，所需要的额外信息量。

**KL 散度的性质**：
- 非负；KL 散度为 0 当且仅当P 和 Q 在离散型变量的情况下是相同的分布，或者在连续型变量的情况下是“几乎处处”相同的
- 不对称；<a href="https://www.codecogs.com/eqnedit.php?latex=D_p(q)&space;!=&space;D_q(p)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?D_p(q)&space;!=&space;D_q(p)" title="D_p(q) != D_q(p)" /></a>

**交叉熵**（cross-entropy）：

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=H_P(Q)&space;=&space;-&space;\mathbb{E}_{\mathrm{X}&space;\sim&space;P}&space;\log&space;Q(x)&space;=&space;-&space;\sum_{x&space;\in&space;\mathrm{X}}P(x)&space;\log&space;Q(x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?H_P(Q)&space;=&space;-&space;\mathbb{E}_{\mathrm{X}&space;\sim&space;P}&space;\log&space;Q(x)&space;=&space;-&space;\sum_{x&space;\in&space;\mathrm{X}}P(x)&space;\log&space;Q(x)" title="H_P(Q) = - \mathbb{E}_{\mathrm{X} \sim P} \log Q(x) = - \sum_{x \in \mathrm{X}}P(x) \log Q(x)" /></a></div>

> [信息量，信息熵，交叉熵，KL散度和互信息（信息增益）](https://blog.csdn.net/haolexiao/article/details/70142571) - CSDN博客

**交叉熵与 KL 散度的关系**：

<div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=H_P(Q)&space;=&space;H(P)&space;&plus;&space;D_P(Q)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?H_P(Q)&space;=&space;H(P)&space;&plus;&space;D_P(Q)" title="H_P(Q) = H(P) + D_P(Q)" /></a></div>

**针对 Q 最小化交叉熵等价于最小化 P 对 Q 的 KL 散度**，因为 Q 并不参与被省略的那一项。

最大似然估计中，最小化 KL 散度其实就是在最小化分布之间的交叉熵。

> 《深度学习》 ch5.5 - 最大似然估计

**求投掷均匀正六面体骰子的熵**

- 问题描述：向空中投掷硬币，落地后有两种可能的状态，一个是正面朝上，另一个是反面朝上，每个状态出现的概率为1/2。如投掷均匀的正六面体的骰子，则可能会出现的状态有6个，每一个状态出现的概率均为1/6。试通过计算来比较状态的不确定性与硬币状态的不确定性的大小。

- 答：

    硬币：

    <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=-&space;\sum^{n}_{i=1}P(X_i)&space;\log&space;P(X_i)&space;=&space;-2&space;*&space;\frac{1}{2}&space;*&space;\log&space;P(\frac{1}{2})&space;\approx&space;1&space;\text{bit}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?-&space;\sum^{n}_{i=1}P(X_i)&space;\log&space;P(X_i)&space;=&space;-2&space;*&space;\frac{1}{2}&space;*&space;\log&space;P(\frac{1}{2})&space;\approx&space;1&space;\text{bit}" title="- \sum^{n}_{i=1}P(X_i) \log P(X_i) = -2 * \frac{1}{2} * \log P(\frac{1}{2}) \approx 1 \text{bit}" /></a></div>

    六面体：

    <div align="center"><a href="https://www.codecogs.com/eqnedit.php?latex=-&space;\sum^{n}_{i=1}P(X_i)&space;\log&space;P(X_i)&space;=&space;-6&space;*&space;\frac{1}{6}&space;*&space;\log&space;P(\frac{1}{6})&space;\approx&space;2.6&space;\text{bit}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?-&space;\sum^{n}_{i=1}P(X_i)&space;\log&space;P(X_i)&space;=&space;-6&space;*&space;\frac{1}{6}&space;*&space;\log&space;P(\frac{1}{6})&space;\approx&space;2.6&space;\text{bit}" title="- \sum^{n}_{i=1}P(X_i) \log P(X_i) = -6 * \frac{1}{6} * \log P(\frac{1}{6}) \approx 2.6 \text{bit}" /></a></div>

## 12. 数据增强方法

> [数据增强方法总结](https://blog.csdn.net/Iriving_shu/article/details/78762567) - CSDN

常用的数据增强方法有：

- 旋转 | 反射变换(Rotation/reflection): 随机旋转图像一定角度; 改变图像内容的朝向;
- 翻转变换(flip): 沿着水平或者垂直方向翻转图像;
- 缩放变换(zoom): 按照一定的比例放大或者缩小图像;
- 平移变换(shift): 在图像平面上对图像以一定方式进行平移;
- 可以采用随机或人为定义的方式指定平移范围和平移步长, 沿水平或竖直方向进行平移. 改变图像内容的位置;
- 尺度变换(scale): 对图像按照指定的尺度因子, 进行放大或缩小; 或者参照SIFT特征提取思想, 利用指定的尺度因子对图像滤波构造尺度空间. 改变图像内容的大小或模糊程度;
- 对比度变换(contrast): 在图像的HSV颜色空间，改变饱和度S和V亮度分量，保持色调H不变. 对每个像素的S和V分量进行指数运算(指数因子在0.25到4之间), 增加光照变化;
- 噪声扰动(noise): 对图像的每个像素RGB进行随机扰动, 常用的噪声模式是椒盐噪声和高斯噪声;
- 颜色变化：在图像通道上添加随机扰动。
- 输入图像随机选择一块区域涂黑，参考《Random Erasing Data Augmentation》

## 13. PCA原理

> [主成分分析（PCA）原理详解](https://zhuanlan.zhihu.com/p/37777074) - 知乎
>
> [PCA的数学原理及推导证明](https://zhuanlan.zhihu.com/p/26951643) - 知乎
>
> [主成分分析PCA工作原理和简单介绍](https://blog.csdn.net/suibianshen2012/article/details/51353484) - CSDN
>
> [主成分分析（PCA）原理详解](https://blog.csdn.net/zhongkelee/article/details/44064401) - CSDN
>
> [『 特征降维』PCA原理-Principal Component Analysis](https://blog.csdn.net/shine19930820/article/details/71037209) - CSDN
>
> [主成分分析（PCA）原理总结](https://www.cnblogs.com/pinard/p/6239403.html) - 刘建平Pinard

> 在多元统计分析中，**主成分分析**（**Principal components analysis**，**PCA**）是一种分析、简化数据集的技术。主成分分析经常用于减少数据集的维数，同时保持数据集中的对方差贡献最大的特征。这是通过保留低阶主成分，忽略高阶主成分做到的。这样低阶成分往往能够保留住数据的最重要方面。

PCA在机器学习中经常被用到，是数据预处理的重要步骤。它主要基于以下考虑：

- 高维特征中很多特征之间存在相关性，含有冗余信息
- 相比于低维数据，高维数据计算更复杂

PCA的原理就是将原来的样本数据投影到一个新的空间中，相当于我们在矩阵分析里面学习的将一组矩阵映射到另外的坐标系下。通过一个转换坐标，也可以理解成把一组坐标转换到另外一组坐标系下，但是在新的坐标系下，表示原来的原本不需要那么多的变量，只需要原来样本的**最大的一个线性无关组的特征值对应的空间的坐标即可**。

**一般来说，PCA降维后的每个样本的特征的维数，不会超过训练样本的个数**，因为超出的特征是没有意义的。

**降维的必要性：**

1. 多重共线性--预测变量之间相互关联。多重共线性会导致解空间的不稳定，从而可能导致结果的不连贯。
2. 高维空间本身具有稀疏性。一维正态分布有68%的值落于正负标准差之间，而在十维空间上只有0.02%。
3. 过多的变量会妨碍查找规律的建立。
4. 仅在变量层面上分析可能会忽略变量之间的潜在联系。例如几个预测变量可能落入仅反映数据某一方面特征的一个组内。

**降维的目的：**

1. 减少预测变量的个数
2. 确保这些变量是相互独立的
3. 提供一个框架来解释结果

降维的方法有：主成分分析、因子分析、用户自定义复合等。

**PCA算法**

将原始数据按列组成n行m列矩阵X

1. 将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值。
2. 求出协方差矩阵C=1mXXTC=1mXXT
3. 求出协方差矩阵的特征值及对应的特征向量
4. 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P
5. Y=PX即为降维到k维后的数据

**PCA算法总结**

这里对PCA算法做一个总结。作为一个非监督学习的降维方法，它只需要特征值分解，就可以对数据进行压缩，去噪。因此在实际场景应用很广泛。为了克服PCA的一些缺点，出现了很多PCA的变种，比如第六节的为解决非线性降维的KPCA，还有解决内存限制的增量PCA方法Incremental PCA，以及解决稀疏数据降维的PCA方法Sparse PCA等。

PCA算法的主要优点有：

- 仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　
- 各主成分之间正交，可消除原始数据成分间的相互影响的因素。
- 计算方法简单，主要运算是特征值分解，易于实现。

PCA算法的主要缺点有：

- 主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。
- 方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。

> **正常的PCA应该是协方差矩阵求特征值和特征向量**

## 14. 特征值和特征向量的含义

> [矩阵乘法的本质是什么？***](https://www.zhihu.com/question/21351965) - 知乎
>
> [如何理解矩阵特征值？***](https://www.zhihu.com/question/21874816/answer/181864044) - 知乎
>
> [特征值（eigenvalue）特征向量（eigenvector）特征值分解（eigenvalue decomposition）](https://blog.csdn.net/zhengwei223/article/details/78913898) - CSDN

**矩阵所充当的映射,实际上就是对特征向量的缩放,每个特征向量的缩放程度就是特征值.**

- 特征值就是运动的速度

- 特征向量就是运动的方向

- 特征值就是拉伸的大小

- 特征向量指明了拉伸的方向

> **矩阵的乘法，本质是一种运动。**

<img src="_asset/特征值和特征向量.png">

<img src="_asset/特征空间.png">

对于方阵而言，矩阵不会进行维度的升降，所以矩阵代表的运动实际上只有两种：

- 旋转
- 拉伸

> 特征值只有方阵才可能有 因为要想Ax=tx t是特征值 则必然要求A的列数=x的行数=A的行数
>
> 而条件数就不一样了 A的条件数被定义为A的范数乘以A的广义逆的范数 非方阵也是有可能有广义逆的 其广义逆是(A的共轭转置乘以A)的逆乘以A的共轭转置 只要A是行满秩或者列满秩的 其广义逆就存在 从而有条件数
>
> 对于2范数意义下的的条件数 其值为A的最大奇异值除以A的最小奇异值

## 15. SGD 中 S(stochastic)代表什么

> [为什么我们更宠爱“随机”梯度下降？（SGD）](https://zhuanlan.zhihu.com/p/28060786) - 知乎
>
> [从动力学角度看随机梯度下降：一些小启示](https://zhuanlan.zhihu.com/p/39354316) - 知乎
>
> [深度学习最全优化方法总结比较（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）](https://zhuanlan.zhihu.com/p/22252270) - 知乎

**直觉上结论是：相对于非随机算法，SGD 能更有效的利用信息，特别是信息比较冗余的时候。**

**实验上结论是：相对于非随机算法， SGD 在前期迭代效果卓越。**

**理论上结论是：如果样本数量大，那么 SGD的计算复杂度依然有优势。**

## 16. 数据预处理的方法

> [数据预处理与特征选择](https://blog.csdn.net/u010089444/article/details/70053104) - CSDN
>
> [机器学习-常见的数据预处理](https://blog.csdn.net/yehui_qy/article/details/53791006) - CSDN
>
> [机器学习——字典学习/稀疏编码学习笔记](https://zhuanlan.zhihu.com/p/26015351)

> 数据预处理和特征选择是数据挖掘与机器学习中关注的重要问题，坊间常说：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。特征工程就是将原始数据转化为有用的特征，更好的表示预测模型处理的实际问题，提升对于未知数据的预测准确性。

### 16.1 数据挖掘中使用的数据的原则

- 尽可能赋予属性名和属性值明确的含义；
- 去除惟一属性；
- 去除重复性；
- 合理选择关联字段。

### 16.2 常见的数据预处理方法

- 数据清洗：数据清洗的目的不只是要消除错误、冗余和数据噪音，还要能将按不同的、不兼容的规则所得的各种数据集一致起来。
- 数据集成：将多个数据源中的数据合并，并存放到一个一致的数据存储（如数据仓库）中。这些数据源可能包括多个数据库、数据立方体或一般文件。
- 数据变换：找到数据的特征表示，用维度变换来减少有效变量的数目或找到数据的不变式，包括规格化、规约、切换和投影等操作。
- 数据规约：是在对发现任务和数据本身内容理解的基础上，寻找依赖于发现目标的表达数据的有用特征，以缩减数据模型，从而在尽可能保持数据原貌的前提下最大限度的精简数据量，主要有两个途径：属性选择和数据抽样，分别针对数据库中的属性和记录。

## 17. 稀疏矩阵

### 17.1 稀疏的问题

稀疏矩阵会导致空间复杂度和时间复杂度的问题。

**空间复杂度**
非常大的矩阵需要大量的内存，而我们想要处理的一些非常大的矩阵是稀疏的。

> *在实践中，大多数大型矩阵都是稀疏的——几乎所有的项都为零。*

—第465页，《线性代数介绍》（Introduction to Linear Algebra），第五版，2016年。

一个非常大的矩阵的例子是，因为它太大而不能存储在内存中，这是一个显示从一个网站到另一个网站的链接的链接矩阵。一个更小的稀疏矩阵的例子可能是一个单词或术语的出现矩阵，在一本书中与所有已知的英语单词对应。

在这两种情况下，所包含的矩阵都是稀疏的，其零值比数据值要多。将这些稀疏矩阵表示为稠密矩阵的问题是对内存的要求，并且必须为矩阵中的每个32位或64位零值做出分配。

这显然是对内存资源的浪费，因为这些零值不包含任何信息。

**时间复杂度**
假设一个非常大的稀疏矩阵可以适应内存，我们将需要对这个矩阵执行操作。

简单地说，如果矩阵包含了大部分零值，也就是没有数据，那么在这个矩阵中执行操作可能需要很长时间，其中的大部分计算都需要或将零值相加或相乘。

> *在这样的问题上使用线性代数的一般方法是很浪费的，因为大多数O(N^3)算术运算都用于求解方程组或反转（invert）包含零操作数的矩阵。*

—第75页，《数值分析：科学计算的艺术》（Numerical Recipes: The Art of Scientific Computing），第三版，2007年。

这是矩阵运算的时间复杂度增加的问题，随着矩阵的大小而增加。

当我们考虑到即使是琐碎的机器学习方法可能需要对每一行、列甚至整个矩阵进行许多操作时，这个问题也会变得更加复杂，从而导致执行时间大大延长。

### 17.2 机器学习中的稀疏矩阵

稀疏矩阵在应用机器学习中经常出现。

在这一节中，我们将讨论一些常见的例子，以激发你对稀疏问题的认识。

**数据**
稀疏矩阵在某些特定类型的数据中出现，最值得注意的是记录活动的发生或计数的观察。

三个例子包括:

- 用户是否在一个电影目录中有曾经看过的电影。
- 用户是否在一个产品目录中有已经购买过的产品。
- 在一个歌曲目录中数出收听过的歌曲的数量。

**数据准备**
在准备数据时，稀疏矩阵会出现在编码方案中。

三种常见的例子包括:

- 独热编码，用来表示分类数据为稀疏的二进制向量。
- 计数编码，用于表示文档中词汇的频率。
- TF-IDF编码，用于表示词汇中标准化的单词频率得分。

**领域研究**
机器学习中的一些领域必须开发专门的方法来解决稀疏问题，因为输入的数据几乎总是稀疏的。

三个例子包括:

- 用于处理文本文档的自然语言处理。
- 推荐系统在一个目录中进行产品使用。
- 当处理图像时计算机视觉包含许多黑色像素（black pixel）。

> *如果在语言模型中有100,000个单词，那么特征向量长度为100,000，但是对于一个简短的电子邮件来说，几乎所有的特征都是0。*

—第22页，《人工智能：一种现代方法》（Artificial Intelligence: A Modern Approach），第三版，2009年。

### 17.3 处理稀疏矩阵

表示和处理稀疏矩阵的解决方案是使用另一个数据结构来表示稀疏数据。

零值可以被忽略，只有在稀疏矩阵中的数据或非零值需要被存储或执行。

多个数据结构可以用来有效地构造一个稀疏矩阵;下面列出了三个常见的例子。

- Dictionary of Keys。在将行和列索引映射到值时使用字典。
- List of Lists。矩阵的每一行存储为一个列表，每个子列表包含列索引和值。
- Coordinate List。一个元组的列表存储在每个元组中，其中包含行索引、列索引和值。

还有一些更适合执行高效操作的数据结构;下面列出了两个常用的示例。

- 压缩的稀疏行。稀疏矩阵用三个一维数组表示非零值、行的范围和列索引。
- 压缩的稀疏列。与压缩的稀疏行方法相同，除了列索引外，在行索引之前被压缩和读取。

被压缩的稀疏行，也称为CSR，通常被用来表示机器学习中的稀疏矩阵，因为它支持的是有效的访问和矩阵乘法。

> - [机器学习稀疏矩阵简介(附Python代码)](https://zhuanlan.zhihu.com/p/35032245) - 知乎
> - [一篇关于机器学习中的稀疏矩阵的介绍](https://zhuanlan.zhihu.com/p/34534763) - 知乎

### 17.4 推荐系统

> 嵌入层甚至可以用来处理推荐系统中的稀疏矩阵问题。

> - [深度学习系列 4: 为什么你需要使用嵌入层](https://juejin.im/post/599183c6f265da3e2e5717d2) - 掘金

### 17.5 [推荐系统]欧氏距离和余弦相似度

> **前者是看成坐标系中两个点，来计算两点之间的距离；**
>
> **后者是看成坐标系中两个向量，来计算两向量之间的夹角。**

> 余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，夹角等于0，即两个向量相等，这就叫"余弦相似性"。

> - [欧氏距离和余弦相似度](https://blog.csdn.net/SunnyYoona/article/details/39721485) - CSDN
> - [余弦计算相似度度量](https://blog.csdn.net/SunnyYoona/article/details/39721205) - CSDN

## 18. 特征提取的方法和过程

> [机器学习系列：（三）特征提取与处理](https://blog.csdn.net/u013719780/article/details/51743867) - CSDN
>
> [图像特征提取三大法宝：HOG特征，LBP特征，Haar特征](http://dataunion.org/20584.html) - 数盟
>
> [特征选择与特征提取](https://blog.csdn.net/henryczj/article/details/41284201) - CSDN

> - 特征选择是指去掉无关特征，保留相关特征的过程，也可以认为是从所有的特征中选择一个最好的特征子集。特征选择本质上可以认为是降维的过程。
> - 特征提取是指将机器学习算法不能识别的原始数据转化为算法可以识别的特征的过程。比如说，文本是由一系列文字组成的，这些文字在经过分词后会形成一个词语集合，对于这些词语集合（原始数据），机器学习算法是不能直接使用的，我们需要将它们转化成机器学习算法可以识别的数值特征（固定长度的向量表示），然后再交给机器学习的算法进行操作。再比如说，图片是由一系列像素点构（原始数据）成的，这些像素点本身无法被机器学习算法直接使用，但是如果将这些像素点转化成矩阵的形式（数值特征），那么机器学习算法就可以使用了。

模式识别的大致流程如下：

<img src="_asset/模式识别.png">

特征提取与选择是在分类器设计之前完成，它主要的工作是针对数据原始特征的缺陷，降低特征维数，提高分类器的设计与性能。

## 19. 监督学习／迁移学习／半监督学习／弱监督学习／非监督学习？

### 19.1 机器学习算法的类型

**监督学习（Supervised Learning）**

监督学习是基于样本集进行预测的算法。例如历史的销售额可以用来预测未来商品的价格。监督学习算法拥有一个由标记训练样本构成的输入变量和一个期望的输出变量。采用算法分析训练数据能够学习出输入到输出的映射函数，通过训练样本到期望结果的泛化预测新的未知样本的输出结果：

- **分类（Classification）**：如果数据用来预测一个类别变量，那么监督学习算法又称作分类，比如对一张图片标注标签（狗或者猫）。如果只有两个标签，则称作二分类问题（binary classification），当类别大于两个时，称作多类别分类问题（multi-class classification）
- **回归（Regression）**：当预测变量为连续变量时，问题就转化为一个回归问题
- **预测（Forecasting）**：一种基于过去和现在数据预测未来的处理过程，主要用于分析事物发展的趋势。例如，基于过去几年和今年的销售额估计明年的销售额问题

**半监督学习（Semi-supervised Learning）**

监督学习一个主要问题是有标签数据的获取非常耗时耗力。如果标记数据有限，可以采用未标记样本增强监督学习的性能。由于算法并不是完全监督的，所以称作半监督算法。半监督学习算法可以利用未标记样本和少量标记样本提升学习算法精度。

**非监督学习（Unsupervised Learning）**

非监督学习算法完全使用未标记数据，挖掘数据潜在的固有模式，例如聚类结构、低维流形或者稀疏树和图。

- 聚类（Clustering）：对样本数据进行分组，使得同一分组（类别）下的数据比不同分组的数据更相似，聚类算法常用于将整个数据集划分为多个组，然后对每个组内的数据进行分析，有助于找到数据内存的模式。
- 降维（Dimension Reduction）：减少可能使用的变量数目。在很多实际应用中，原始数据可能维度很高，而且特征之间存在冗余性或与任务无关，这种情况下降维有助于找到变量之间真实的潜在关系。

**强化学习（Reinforcement Learning）**

强化学习基于环境中智能体的反馈分析并优化其行为，算法在不同场景下进行测试从而发现能够产生最高奖励的动作，而不是被动地选择动作。试验与误差和延迟奖励是强化学习区别其他算法的特性。

### 19.2 迁移学习

> 迁移学习(Transfer learning) 顾名思义就是就是把已学训练好的模型参数迁移到新的模型来帮助新模型训练。考虑到大部分数据或任务是存在相关性的，所以通过迁移学习我们可以将已经学到的模型参数（也可理解为模型学到的知识）通过某种方式来分享给新模型从而加快并优化模型的学习效率不用像大多数网络那样从零学习（starting from scratch，tabula rasa）。

> - [深度学习 -> 强化学习 ->迁移学习（杨强教授报告）***)](https://blog.csdn.net/jiandanjinxin/article/details/54133521) - CSDN
> - [什么是迁移学习 (Transfer Learning)？这个领域历史发展前景如何？***](https://www.zhihu.com/question/41979241/answer/208177153)
> - [独家：一文读懂迁移学习（附学习工具包）](http://www.xtecher.com/Xfeature/view?aid=7383) - THU数据派

## 20. 树模型的特征选择中除了信息增益、信息增益比、基尼指数这三个外，还有哪些？

TODO

## 21. 最小二乘与极大似然函数的关系？

> [最小二乘法和最大似然法](http://blog.sina.com.cn/s/blog_4b12446d010191ri.html)
>
> [线性回归的损失函数为什么用最小二乘不用似然函数？](https://blog.csdn.net/Beyond_2016/article/details/80030414)

对于最小二乘法，当从模型总体随机抽取n组样本观测值后，最合理的参数估计量应该使得模型能最好地拟合样本数据，也就是估计值和观测值之差的平方和最小。而对于最大似然法，当从模型总体随机抽取n组样本观测值后，最合理的参数估计量应该使得从模型中抽取该n组样本观测值的概率最大。显然，这是从不同原理出发的两种参数估计方法。

在最大似然法中，通过选择参数，使已知数据在某种意义下最有可能出现，而某种意义通常指似然函数最大，而似然函数又往往指数据的概率分布函数。与最小二乘法不同的是，最大似然法需要已知这个概率分布函数，这在时间中是很困难的。一般假设其满足正态分布函数的特性，在这种情况下，最大似然估计和最小二乘估计相同。

最小二乘法以估计值与观测值的差的平方和作为损失函数，极大似然法则是以最大化目标值的似然概率函数为目标函数，**从概率统计的角度处理线性回归并在似然概率函数为高斯函数的假设下同最小二乘建立了的联系。**

## 22. 哪些机器学习算法不需要做归一化处理？

> [机器学习中，为何要经常对数据做归一化](https://www.julyedu.com/question/big/kp_id/23/ques_id/1011)

在实际应用中，通过梯度下降法求解的模型一般都是需要归一化的，比如线性回归、logistic回归、KNN、SVM、神经网络等模型。

**但树形模型不需要归一化**，**因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、随机森林(Random Forest)。**

其他如管博士所说，我归一化和标准化主要是为了使计算更方便 比如两个变量的量纲不同 可能一个的数值远大于另一个那么他们同时作为变量的时候 可能会造成数值计算的问题，比如说求矩阵的逆可能很不精确 或者梯度下降法的收敛比较困难，还有如果需要计算欧式距离的话可能 量纲也需要调整 所以我估计lr 和 knn 标准化一下应该有好处。

至于其他的算法 我也觉得如果变量量纲差距很大的话 先标准化一下会有好处。


## 23. 训练误差、泛化误差；过拟合、欠拟合；模型容量，表示容量，有效容量，最优容量的概念； 奥卡姆剃刀原则*

**“奥卡姆剃刀”三法**

　　对于组织在[目标设置](https://wiki.mbalib.com/wiki/%E7%9B%AE%E6%A0%87%E8%AE%BE%E7%BD%AE)与执行过程中因上述种种原因而出现的目标曲解与置换，有一个根本的解决之道，即“无情地剔除所有累赘”，这也正是“奥卡姆剃刀”所倡导的“简化”法则：保持事物的简单化是对付复杂与繁琐的最有效方式。具体而言，有三种措施可以帮助我们避免目标曲解与置换现象的发生：

　　**1、精兵简政，不断简化组织结构**

　　[组织结构扁平化](https://wiki.mbalib.com/wiki/%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84%E6%89%81%E5%B9%B3%E5%8C%96)与组织结构非层级化已经成为企业[组织变革](https://wiki.mbalib.com/wiki/%E7%BB%84%E7%BB%87%E5%8F%98%E9%9D%A9)的基本趋势。在新型的组织结构中，传统的企业组织结构中严格的[等级制度](https://wiki.mbalib.com/wiki/%E7%AD%89%E7%BA%A7%E5%88%B6%E5%BA%A6)已经不复存在，组织中上下有序的传统规则被淡化，员工之间的关系是平等的分工合作关系，基层员工被赋予更多的权力，他们有可能参与部门目标甚至于[组织目标](https://wiki.mbalib.com/wiki/%E7%BB%84%E7%BB%87%E7%9B%AE%E6%A0%87)的制定，组织内的信息不再是上下级之间的单向传递，而是一种网络化的即时式[双向沟通](https://wiki.mbalib.com/wiki/%E5%8F%8C%E5%90%91%E6%B2%9F%E9%80%9A)。在这种组织中，顾客的需要成为员工行动的向导，人们的行为具有明确的目标导向。同时，由于员工的积极参与，组织目标与个人目标之间的矛盾得到最大程度地消除。

　　**2、关注组织的核心价值，始终将组织资源集中于自己的专长**

　　也就是说，组织需要从众多可供选择的业务中筛选出最重要的、拥有[核心竞争能力](https://wiki.mbalib.com/wiki/%E6%A0%B8%E5%BF%83%E7%AB%9E%E4%BA%89%E8%83%BD%E5%8A%9B)的业务，在自己最具竞争优势的领域确定组织的目标。这样，才能确保组织集中精力，就可以以最少的代价获得最丰厚的[利润](https://wiki.mbalib.com/wiki/%E5%88%A9%E6%B6%A6)。反之，如果目标数量过多，往往会使经营者难以同时兼顾太多的业务，从而顾此失彼。[韦尔奇](https://wiki.mbalib.com/wiki/%E9%9F%A6%E5%B0%94%E5%A5%87)上任[通用电气公司](https://wiki.mbalib.com/wiki/%E9%80%9A%E7%94%A8%E7%94%B5%E6%B0%94%E5%85%AC%E5%8F%B8)总裁时，从简洁高效的角度出发，提出[“非一即二”原则](https://wiki.mbalib.com/wiki/%E2%80%9C%E9%9D%9E%E4%B8%80%E5%8D%B3%E4%BA%8C%E2%80%9D%E5%8E%9F%E5%88%99)：必须把本产品做成数一数二的产品，否则一律卖掉。

　　**3、简化流程，避免不必要的文书作业**

　　事实上，由于个体受自身[思维方式](https://wiki.mbalib.com/wiki/%E6%80%9D%E7%BB%B4%E6%96%B9%E5%BC%8F)的限制，简单的信息远比复杂的信息更有利于人们的思考与[决策](https://wiki.mbalib.com/wiki/%E5%86%B3%E7%AD%96)。因此一个优秀企业的主要特征，就是他们知道如何保持事情的简单化，不管多复杂的事情都能将其变得简单易行。

　　尽管导致组织目标曲解与置换的原因很多，但奥卡姆剃刀定律对解决目标的曲解与置换为我们提供了一种“简单”的理念与思路。

> 奥卡姆剃刀定律，是由14世纪逻辑学家、圣方济各会修士奥卡姆的威廉（William of Occam，约1285年至1349年）提出。这个原理称为“如无必要，勿增实体”，即“简单有效原理”。
>
> 应用：
>
> ①做选择时，添加必要条件，提出非必要条件，然后去计算概率，每一项选择的结果出现的概率。

> - [罗胖说的最重要的“奥卡姆剃刀原则”是什么？](https://www.jianshu.com/p/8102cb404a45) - 简书

## 24. 特征工程做的有哪些？非线性可分的情况怎么处理的？

> [特征工程到底是什么？](https://www.zhihu.com/question/29316149) - 知乎
>
> [特征工程实用技巧](https://zhuanlan.zhihu.com/p/26444240) - 知乎
>
> [SVM边学边总结系列——非线性可分情况](https://blog.csdn.net/sgfmby1994/article/details/52432828) - CSDN
>
> [机器学习入门教程：Python测试线性可分性的方法](http://www.atyun.com/14182.html)

**类别特征**：

类别特征，表示某个数据点属于某一个类别，或具有某一种类的特性。一列类别特征，默认用**自然数**表示（可以用LabelEncoder将字符串转化为自然数）。

例：颜色、性别、地址、血型、国籍、省、市、邮政编码。

- 自然数编码：默认的编码方式（见上，使用LabelEncoder可以得到），消耗内存小，训练时间快，但是特征的质量不高。

- 热独编码（**One-hot Encoding**）：如果类别特征本身**有顺序**（例：优秀、良好、合格、不合格），那么可以保留单列自然数编码。如果类别特征**没有明显的顺序**（例：红、黄、蓝），则可以使用以下方法：

  [sklearn.preprocessing.OneHotEncoder - scikit-learn 0.18.1 documentation](https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)，用于类别特征的**独热编码（One-Hot Encoding）**。运行结果与LabelBinarizer相似，不过在参数以及输入输出的格式上有细微的差别，参见文档。输出的矩阵是稀疏的，含有大量的0。

  统计学中，独热编码的变种还有effects coding、contrast coding、nonsense coding等编码方式，但在数据挖掘中都不常用。

- 聚类编码：和独热编码相比，聚类编码试图充分利用每一列0与1的信息表达能力。聚类编码时一般需要特定的专业知识（domain knowledge），例如ZIP码可以根据精确度分层为ZIP3、ZIP4、ZIP5、ZIP6，然后按层次进行编码。

- 平均数编码（**mean encoding**）：**平均数编码（mean encoding）**，针对**高基数类别特征**的**有监督编码**。当一个类别特征列包括了极多不同类别时（如家庭地址，动辄上万）时，可以采用。优点：和独热编码相比，节省内存、减少算法计算时间、有效增强模型表现。

  [平均数编码：针对高基数类别特征（类别特征）的数据预处理/特征工程 - 知乎专栏](https://zhuanlan.zhihu.com/p/26308272)

- **只出现一次的类别**：在类别特征列里，有时会有一些类别，在训练集和测试集中总共只出现一次，例如特别偏僻的郊区地址。此时，保留其原有的自然数编码意义不大，不如将所有**频数为1**的类别**合并到同一个新的类别下**。

  注意：如果特征列的频数需要被当做一个新的特征加入数据集，请在上述合并**之前**提取出频数特征。

**数值特征**：

**数值特征（numerical feature）**，可以是连续的（continuous），也可以是离散的（discrete），一般表示为一个实数值。

例：年龄、价格、身高、体重、测量数据。

**不同算法对于数值特征的处理要求不同**。下文中的一些数据处理方法（3.2.1、3.2.2、3.2.3），因为是针对某一特征列的单调变换，所以不会对基于决策树的算法（随机森林、gbdt）产生任何影响。一般而言，决策树类算法不需要预处理数值特征。

- **标准化（Standardization）**：[sklearn.preprocessing.StandardScaler - scikit-learn 0.18.1 documentation](https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)，转换为Z-score，使数值特征列的算数平均为0，方差（以及标准差）为1。不免疫outlier。

  <a href="https://www.codecogs.com/eqnedit.php?latex=x'&space;=&space;\frac{x&space;-&space;\mu}{\sigma}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?x'&space;=&space;\frac{x&space;-&space;\mu}{\sigma}" title="x' = \frac{x - \mu}{\sigma}" /></a>

  [sklearn.preprocessing.RobustScaler - scikit-learn 0.18.1 documentation](https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)。如果数值特征列中存在数值极大或极小的outlier（通过EDA发现），应该使用更稳健（robust）的统计数据：用中位数而不是算术平均数，用分位数（quantile）而不是方差。这种标准化方法有一个重要的参数：（分位数下限，分位数上限），最好通过EDA的数据可视化确定。免疫outlier。

- **归一化（Normalization）**：[sklearn.preprocessing.Normalizer - scikit-learn 0.18.1 documentation](https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html)，把每一行数据归一化，使之有unit norm，norm的种类可以选l1、l2或max。不免疫outlier。

- **区间缩放（scaling）**：[sklearn.preprocessing.MaxAbsScaler - scikit-learn 0.18.1 documentation](https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)，将一列的数值，除以这一列的最大绝对值。不免疫outlier。

  <a href="https://www.codecogs.com/eqnedit.php?latex=x'&space;=&space;\frac{x}{max(|X|)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?x'&space;=&space;\frac{x}{max(|X|)}" title="x' = \frac{x}{max(|X|)}" /></a>

  [sklearn.preprocessing.MinMaxScaler - scikit-learn 0.18.1 documentation](https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)。不免疫outlier。

  <a href="https://www.codecogs.com/eqnedit.php?latex=x'&space;=&space;\frac{x&space;-&space;min(X)}{max(X)&space;-&space;min(X)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?x'&space;=&space;\frac{x&space;-&space;min(X)}{max(X)&space;-&space;min(X)}" title="x' = \frac{x - min(X)}{max(X) - min(X)}" /></a>

**非线性可分情况**：无法用直线(线性模型)将正负实例正确分开。 

**怎么办？？**

引入核函数，通过一个非线性变换将输入空间对应于一个特征空间，使得在输入空间中的超曲面模型对应于特征空间中的超平面模型(支持向量机)，这样，分类问题的学习任务通过在特征空间中求解线性支持向量机就可以完成。

## 25. SVM的核函数了解多少？

> - [SVM 的核函数选择和调参](https://www.jianshu.com/p/0a24eafda4ff) - 简书
> - [svm常用核函数](https://blog.csdn.net/batuwuhanpei/article/details/52354822) - CSDN
> - [svm核函数的理解和选择](https://blog.csdn.net/Leonis_v/article/details/50688766) - CSDN

几种常用的核函数来代替自己构造核函数：

- 线性核函数
- 多项式核函数
- 高斯（RBF）核函数
- sigmoid核函数

选择核函数的方法：

- 如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；
- 如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；
- 如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。

**调参：**

| 核函数                               | 公式                                                         | 调参                                                         |
| ------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| linear kernel                        | ![img](https:////upload-images.jianshu.io/upload_images/1667471-55f50ec52f369bc3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/155/format/webp) |                                                              |
| Polynomial kernel                    | ![img](https:////upload-images.jianshu.io/upload_images/1667471-9d697255b7ddde54.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/279/format/webp) | -d：多项式核函数的最高次项次数，-g：gamma参数，-r：核函数中的coef0 |
| Gaussian radial basis function (RBF) | ![img](https:////upload-images.jianshu.io/upload_images/1667471-0370c098adda9e32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/288/format/webp) | -g：gamma参数，默认值是1/k                                   |
| Sigmoid kernel                       | ![img](https:////upload-images.jianshu.io/upload_images/1667471-5289e8077925cb8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/348/format/webp) | -g：gamma参数，-r：核函数中的coef0                           |

其中有两个重要的参数，即 C（惩罚系数） 和 gamma，**gamma 越大，支持向量越少，gamma 越小，支持向量越多**。

而支持向量的个数影响训练和预测的速度。**C 越高，容易过拟合。C 越小，容易欠拟合**。

## 26. sigmoid函数的导函数的取值范围是多少？

> [sigmoid导函数的取值范围？](https://blog.csdn.net/JZ_Javacy/article/details/80047316) - CSDN

其实就是一元二次方程的y值范围，`0-1/4`

<img src="_asset/sigmoid导数范围.png">





